{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f3673e",
   "metadata": {},
   "source": [
    "## Inference for Gemma3N_Kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47788998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.multimodal.audio import AudioResampler\n",
    "import soundfile as sf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16073843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185e5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model \n",
    "\n",
    "MODEL_PATH = \"/home/mike/unsloth_work/gemma_3n_kin_10000_epochs_3\"\n",
    "\n",
    "llm = LLM(\n",
    "    model=MODEL_PATH,\n",
    "    max_model_len=4096,\n",
    "    max_num_seqs=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions \n",
    "def load_audio_file(filepath: str):\n",
    "    \"\"\" Load and return (audio_array, sampling_rate) \"\"\"\n",
    "    audio, sr = sf.read(filepath, dtype='float32')\n",
    "    if len(audio.shape) > 1:\n",
    "        # Mono conversion\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    return audio, sr\n",
    "\n",
    "def transcribe_audio(xaudio_array: np.ndarray, xsr: int):\n",
    "    '''\n",
    "    given an audio np array and sampling rate\n",
    "    output a transcription \n",
    "    '''\n",
    "    #first resample \n",
    "    # Gemma3N works with sampling rate of 1600\n",
    "    TARGET_SR = 16000\n",
    "    if xsr != TARGET_SR:\n",
    "        xaudio_array = resampler.resample(xaudio_array, orig_sr=sr)\n",
    "        \n",
    "    # Sampling params for transcription\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024,\n",
    "    )        \n",
    "\n",
    "    prompt = (\n",
    "        \"<start_of_turn>user\\n\"\n",
    "        \"<audio_soft_token>\"\n",
    "        \"transcribe this Kinyarwanda audio into text:\\n\"\n",
    "        \"<end_of_turn>\\n\"\n",
    "        \"<start_of_turn>model\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = {\n",
    "        \"prompt\": prompt,\n",
    "        \"multi_modal_data\": {\n",
    "            # Must be a tuple (audio_waveform, sample_rate)\n",
    "            \"audio\": (xaudio_array.astype(np.float32), xsr)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    outputs = llm.generate(inputs, sampling_params)\n",
    "\n",
    "    text = outputs[0].outputs[0].text\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17ea7921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5b692c51b7475f974fe519af5e6cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de25b9e10fa46e19198986f1a15d4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                                              | 0/1 [0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Inzu yubakishije amatafari, imbere hari urugi runini rw'icyuma rurimo ibirahure bibonerana, hejuru y'urwo rugi hari amagambo yanditseho arimo amabara atandukanye nk'umutuku, ubururu ndetse n'umuhondo, n'icyatsi.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test \n",
    "\n",
    "#xfile = '/media/mike/SSD4T/__staging/AI_Training_dset/audio_qwenasr/wavs/0yb6EzFR1y7aKNsQogml.wav'\n",
    "xfile = '/media/mike/SSD4T/__staging/AI_Training_dset/audio_qwenasr/wavs/0yl9ZizCKe1P83rP11uR.wav'\n",
    "q1, q2 = load_audio_file(xfile)\n",
    "\n",
    "transcribe_audio(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1759e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01350a41",
   "metadata": {},
   "source": [
    "## test with examples from validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f56f936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import random \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25092995",
   "metadata": {},
   "outputs": [],
   "source": [
    "xjson_file = '/media/mike/SSD4T/__staging/AI_Training_dset/audio_qwenasr/train.jsonl'\n",
    "\n",
    "with open(xjson_file , 'r') as xff:\n",
    "    xdata = [json.loads(line) for line in xff.readlines()]\n",
    "    \n",
    "xlist =  random.sample(xdata, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e31b4c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9385d0cc3d4e8c92246751de367039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be97de4b18674ec386fe054e21920081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                                              | 0/1 [0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffd5f1352bf4e2dba9e1c6c51646e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cdc72324ce480c8c33944148cc76bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                                              | 0/1 [0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79cb13191b4484c92c71d771e45be8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fdae78c6344070adc5c3b0b78b2b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                                              | 0/1 [0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c86b9ff0cb4e02b31e1729c052fdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0396bcc2dbb04058853641a61708317a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                                              | 0/1 [0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79dd4fcb109459a8fabbf493becffa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b51240cc81487a9ce91d74ec1eae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                                              | 0/1 [0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'Xgd5saAKCG3ors7QB2hw',\n",
       "  'text_ref': \"Ni abanyeshuri bicaye hasi, bambaye amashati y'igitare, harimo abambaye n'imipira yimbeho y'icyatsi bicaye munsi y'ibiti.\",\n",
       "  'text_tra': \"Ni abanyeshuri bicaye hasi, bambaye amashati y'igare, harimo abambaye n'imipira y'imbeho y'icyatsi, bicaye munsi y'ibiti.\"},\n",
       " {'id': 'noTBwL8uwd42UltUUUNg',\n",
       "  'text_ref': \"Abantu benshi b'ingeri zitandukanye abagore n'abagabo bateraniye hamwe mu nzu irimo ibikoresho by'ikoranabuhanga byinjiza umwuka mwiza mu cyumba barimo, bicaye ku ntebe z'umukara ku meza imbere hari ibikoresho bitandukanye birimo ibikapu byabo.\",\n",
       "  'text_tra': \"Abantu benshi b'ingeri zitandukanye abagore n'abagabo bateraniye hamwe mu nzu irimo ibikoresho by'ikoranabuhanga byiciza umuka mwiza mu cyumba barimo bicaye ku ntebe z'umukara ku meza imbere hari ibikoresho bitandukanye birimo ibikapu by'aho.\"},\n",
       " {'id': 'ZCxUSnQJXG50f6iU4noW',\n",
       "  'text_ref': \"Igikorwa cy'umuganda rusange cyabaye uyu munsi mu Karere ka Muhanga, umuyobozi ushinzwe abinjira n'abasohoka mu Karere yemeje ko na byo bikwiye gukurikizwa.\",\n",
       "  'text_tra': \"Mu gikirahwa cy'umuganda rusange cyabaye uyu munsi mu karere ka Muhanga, umuyoboza ushinzwe abinjira n'abasoboka mu karere, yemeje ko nabyo bikwiye gukurikizwa.\"},\n",
       " {'id': 'ZYx5q5ThOs1AER5sLEhY',\n",
       "  'text_ref': \"Icyapa kinini gishaje gifite ubuso bw'umweru, kiriho idarapo y'u Rwanda ndetse n'ikirangantego cya Repubulika y'u Rwanda, cyanditsweho amagambo ari mu ibara ry'umukara agaragaza: Akarere ka Nyagatare, Umurenge wa Gatunda, Akagari ka Nyamirembe.\",\n",
       "  'text_tra': \"Icyapa kinini gishaje, gifite ubuso bw'umweru, kiriho idapo ry'u Rwanda, ndetse n'ikirangantego ry'Repu y'u Rwanda, cyanditsweho amagambo, ari mu ibara ry'umukara, agaragaza akarere k'i Kacyatare, muringe Gatunda, akarere k'i Kamirebe.\"},\n",
       " {'id': 'CG8FlcqjyxySonPYCFyI',\n",
       "  'text_ref': \"Mu bigo bigiye bitandukanye ndetse n'ahantu hahurira abantu benshi tuhasanga parikingi. parikingi ni ahantu habikwa ibinyabiziga by'abagannye aho hantu, mu buryo bwo gucungirwa umutekano, ndetse no kugabanya akajagari. Izi ni imodoka ziri muri parikingi, bigaragara ko zisa neza.\",\n",
       "  'text_tra': \"Mu bigo bi byigiye bitandukanye ndetse n'ahantu hahurira abantu benshi tuhasanga parking, parking ni ahantu habikwa ibinyabiziga by'abagararnyahohanu mu buryo bwo gucungira umutekano ndetse no kugabanya akajagari, izi ni  imodoka zirimo parking bigaragara ko zisa neza.\"}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlist_results = []\n",
    "\n",
    "for q1 in xlist:\n",
    "    xpath = q1['audio']\n",
    "    xid = xpath.split('/')[-1:][0].replace('.wav', '')\n",
    "    xtext_ref = q1['text'].split('<asr_text>')[1]    \n",
    "    \n",
    "    q1, q2 = load_audio_file(xpath)\n",
    "    q3 = transcribe_audio(q1,q2)\n",
    "    #result_dict \n",
    "    xdict = {}\n",
    "    xdict['id'] = xid \n",
    "    xdict['text_ref'] = xtext_ref\n",
    "    xdict['text_tra'] = q3  \n",
    "    xlist_results.append(xdict)\n",
    "    \n",
    "\n",
    "t1 = pd.DataFrame(xlist_results)\n",
    "    \n",
    "print(t1.head())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad2b2baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "t1.to_excel('test_transcription.xlsx', index=False)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vllm_audio)",
   "language": "python",
   "name": "vllm_audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
